CREATE OR REPLACE EDITIONABLE PACKAGE "PCK_BACKUP" is
    --
    PROCEDURE daily_job;
    --
end;
/
CREATE OR REPLACE EDITIONABLE PACKAGE BODY "PCK_BACKUP" is

    /*
    ** Generate random 16 character password string. Used in order to create encrypted schema export dumpfile
    */
    FUNCTION generate_password(
        no_of_digits             in number DEFAULT 5,
        no_of_special_characters in number DEFAULT 3,
        no_of_lower              in number DEFAULT 4,
        no_of_upper              in number DEFAULT 4
        ) return varchar2
    IS
        password VARCHAR2(4000);
        digits   CONSTANT VARCHAR2(10) := '0123456789';
        lower    CONSTANT VARCHAR2(26) := 'abcdefghijklmnopqrstuvwxyz';
        upper    CONSTANT VARCHAR2(26) := 'ABCDEFGHIJKLMNOPQRSTUVWXYZ';
        special  CONSTANT VARCHAR2(30) := '!"Â£$%^*()-_=+{}[]<>,\|/?;:@#';
    BEGIN
        SELECT LISTAGG(letter, NULL) WITHIN GROUP (ORDER BY DBMS_RANDOM.VALUE)
        INTO   password
        FROM   (
        SELECT SUBSTR(
                 digits,
                 FLOOR(DBMS_RANDOM.VALUE(1, LENGTH(digits) + 1)),
                 1
               ) AS letter
        FROM   DUAL
        CONNECT BY LEVEL <= no_of_digits
        UNION ALL
        SELECT SUBSTR(
                 lower,
                 FLOOR(DBMS_RANDOM.VALUE(1, LENGTH(lower) + 1)),
                 1
               ) AS letter
        FROM   DUAL
        CONNECT BY LEVEL <= no_of_lower
        UNION ALL
        SELECT SUBSTR(
                 upper,
                 FLOOR(DBMS_RANDOM.VALUE(1, LENGTH(upper) + 1)),
                 1
               ) AS letter
        FROM   DUAL
        CONNECT BY LEVEL <= no_of_upper
        UNION ALL
        SELECT SUBSTR(
                 special,
                 FLOOR(DBMS_RANDOM.VALUE(1, LENGTH(special) + 1)),
                 1
               ) AS letter
        FROM   DUAL
        CONNECT BY LEVEL <= no_of_special_characters
        );

        RETURN password;
    END;

    /*
    ** Generate schema datapump export
    */ 
    PROCEDURE datapump_backup(p_repo IN OUT NOCOPY CLOB) IS
        h1 NUMBER;
        
        TYPE t_admin_user IS RECORD(
            id users.id%type,
            email users.email%type);
        TYPE tt_admin_user IS TABLE OF t_admin_user;
        l_admin_users tt_admin_user; 

        l_schema VARCHAR2(30):=sys_context('userenv','current_schema');
        l_filename VARCHAR2(60);
        l_schema_size NUMBER;
        l_status varchar2(4000);
        l_password users.export_pw%type;
        l_json JSON_OBJECT_T;
        l_payload CLOB;
        l_clob CLOB;
        l_body_html CLOB:=
        '<!DOCTYPE html>
         <html>
            <head>
                <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="format-detection" content="telephone=no">
                <meta name="format-detection" content="date=no">
                <meta name="format-detection" content="address=no">
                <meta name="format-detection" content="email=no">
                <style type="text/css">
                    body {
                        font-family: Georgia,sans-serif;
                        font-size: 1rem;
                    }
                    td,
                    th {
                        border: 1px solid rgb(190, 190, 190);
                        padding: 0.5rem;
                    }
                    table {
                        border-collapse: collapse;
                        border: 2px solid rgb(200, 200, 200);
                        width: 100%;
                    }
                    thead {
                        background-color: #d7d9f2;
                    }
                </style>
            </head>
        <body>';
    BEGIN
        pck_core.log('Starting datapump export job for Schema:'||l_schema);

        EXECUTE IMMEDIATE 'TRUNCATE TABLE DBTOOLS$EXECUTION_HISTORY';

        /* 
        ** Delete any files left over from previous operation to avoid ora-39001  
        */
        FOR C IN (SELECT object_name FROM DBMS_CLOUD.LIST_FILES('DATA_PUMP_DIR')) LOOP
            DBMS_CLOUD.DELETE_FILE(directory_name=>'DATA_PUMP_DIR',file_name=>C.object_name);
        END LOOP;

        /* 
        ** Drop any tables not needed in backup
        */
        FOR C IN (SELECT table_name FROM user_tables WHERE table_name IN ('HTMLDB_PLAN_TABLE')) LOOP
            EXECUTE IMMEDIATE 'DROP TABLE ' || C.table_name;
        END LOOP;

        /* 
        ** Get the application user(s) to whom email will be sent on completion 
        */
        SELECT u.id, u.email
          BULK COLLECT INTO l_admin_users
          FROM users u, apex_workspace_developers w 
         WHERE w.first_schema_provisioned=l_schema
           AND w.is_admin='Yes'
           AND w.email=u.email;

        h1 := dbms_datapump.OPEN (operation => 'EXPORT', job_mode => 'SCHEMA', job_name => dbms_scheduler.generate_job_name('EXPORT_SCHEMA_'), version => 'COMPATIBLE'); 

        dbms_datapump.set_parameter(handle => h1, name => 'COMPRESSION', VALUE => 'ALL'); 
        dbms_datapump.set_parameter(handle => h1, name => 'COMPRESSION_ALGORITHM', VALUE => 'MEDIUM'); 
        dbms_datapump.set_parallel(handle => h1, degree => 1); 
        
        l_filename:='EXPORT_SCHEMA.' || l_schema ;
        dbms_datapump.add_file(handle => h1, filename =>  l_filename || '.dmp', 
            directory => 'DATA_PUMP_DIR', filesize => '50M',  filetype => DBMS_DATAPUMP.KU$_FILE_TYPE_DUMP_FILE, reusefile => 1); 
        dbms_datapump.add_file(handle => h1, filename => l_filename || '.log', 
            directory => 'DATA_PUMP_DIR', filetype => DBMS_DATAPUMP.KU$_FILE_TYPE_LOG_FILE, reusefile => 1); 
        
        dbms_datapump.set_parameter(handle => h1, name => 'KEEP_MASTER', VALUE => 0); 
        dbms_datapump.set_parameter(handle => h1, name => 'LOGTIME', VALUE => 'ALL'); 

        dbms_datapump.metadata_filter(handle => h1, name => 'SCHEMA_EXPR', VALUE => 'IN(''' || l_schema || ''')');
        dbms_datapump.metadata_filter(handle => h1, name => 'EXCLUDE_PATH_EXPR', VALUE => 'IN (''DBTOOLS$EXECUTION_HISTORY'',''STATISTICS'',''CLUSTER'',''DB_LINK'',''INDEXTYPE'',''PROCOBJ'',''JOB'',''SCHEDULER'')'); 

        l_password:=generate_password();
        dbms_datapump.set_parameter(handle => h1, name => 'ENCRYPTION_MODE', VALUE => 'PASSWORD'); 
        dbms_datapump.set_parameter(handle => h1, name => 'ENCRYPTION_PASSWORD', VALUE => l_password);

        dbms_datapump.start_job(handle => h1, skip_current => 0, abort_step => 0); 
        dbms_datapump.wait_for_job( handle => h1, job_state => l_status);
        dbms_datapump.detach(handle => h1); 

        /* 
        ** Always send log file to github 
        */
        dbms_cloud_repo.put_file(repo=>p_repo, file_path=>l_filename || '.log', directory_name=>'DATA_PUMP_DIR');

        /* 
        ** Send COMLPETED dump file to Github and save encryption password for any subsequent import 
        */
        IF (l_status='COMPLETED') THEN
            dbms_cloud_repo.put_file(repo=>p_repo, file_path=>l_filename || '.dmp', directory_name=>'DATA_PUMP_DIR');
            FORALL i IN l_admin_users.FIRST..l_admin_users.LAST
                UPDATE users SET export_pw=l_password WHERE id=l_admin_users(i).id;
            
        END IF;

        /* 
        ** Delete old entries in application LOG table
        */
        DELETE log WHERE log_date<current_timestamp-1;
        COMMIT;

        /* 
        ** Send Email to Admin users 
        */
        l_body_html:=l_body_html || '<table role="presentation">';
        l_body_html:=l_body_html || '<thead><tr><th>File Name</th><th>File Size</th><th>Schema Size</th><th>Created</th></tr></thead>';
        l_body_html:=l_body_html || '<tbody>';
        SELECT SUM(bytes) INTO l_schema_size FROM user_segments;
        FOR C IN (SELECT object_name, bytes, last_modified FROM DBMS_CLOUD.LIST_FILES('DATA_PUMP_DIR') WHERE object_name LIKE '%.dmp')
        LOOP
            l_body_html:=l_body_html || '<tr><td>' || C.object_name || '</td><td>' || apex_string_util.to_display_filesize(C.bytes) || '</td>' || apex_string_util.to_display_filesize(l_schema_size) || '<td>' || C.last_modified || '</td></tr>';
        END LOOP;
        l_body_html:=l_body_html || '</tbody></table>';
        l_body_html:=l_body_html || '</html>';

        FOR i IN l_admin_users.FIRST..l_admin_users.LAST
        LOOP
            l_json:=new JSON_OBJECT_T;
            l_json.put('contactEmail',l_admin_users(i).email);
            l_json.put('subject','Daily Backup Job ' || l_status);
            l_json.put('body', l_body_html);
            l_json.put('sourceEmail','backup@adfreesites.com');
            l_payload:=l_json.stringify;
            pck_api.callAWSemailAPI(pMethod=>'POST', pBody=>l_payload, pData=>l_clob);
        END LOOP;

        pck_core.log('Completed datapump schema exports. Final status:' || l_status);
    END;

    /*
    ** Generate and transfer to Github repository the following:
    ** 1. Apex applications
    ** 2. Apex static files
    ** 3. DDL of TABLES and PACKAGES
    */
    PROCEDURE github_backup(
        p_repo IN OUT NOCOPY CLOB)
    IS  
        TYPE t_backup IS RECORD(
            object_type         user_objects.object_type%type,
            object_name         user_objects.object_name%type);

        TYPE tt_backup IS TABLE OF t_backup;
        l_backup tt_backup; 
        
        l_clob CLOB;
        l_blob BLOB;
        l_file_path VARCHAR2(61);
        l_files apex_t_export_files;
        n PLS_INTEGER;
    BEGIN
        /*
        ** Ensure calls to DBMS_METADATA return nicely formatted code without storage and schema details
        */
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'PRETTY',true);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'SQLTERMINATOR',true);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'SEGMENT_ATTRIBUTES',false);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'STORAGE',false);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'TABLESPACE',false);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'EMIT_SCHEMA',false);
        dbms_metadata.set_transform_param(dbms_metadata.session_transform,'COLLATION_CLAUSE','NEVER');

        /*
        ** Build PLSQL collection of all objects to be exported and copied to Github
        */
        SELECT object_type, object_name
          BULK COLLECT INTO l_backup
         FROM
            (
                SELECT object_type,object_name
                FROM user_objects
                WHERE generated='N'
                AND object_type IN ('TABLE','PACKAGE')
                UNION ALL 

                SELECT 'APEX_APPLICATION',TO_CHAR(application_id)
                FROM apex_applications
                WHERE owner=sys_context('userenv','current_schema') 
                UNION ALL 

                SELECT 'APEX_STATIC_FILE',f.application_id || '.' || f.file_name
                FROM apex_application_static_files f, apex_applications a
                WHERE f.application_id=a.application_id
                AND SUBSTR(f.mime_type,INSTR(f.mime_type,'/')+1) IN ('javascript','css')
                AND INSTR(f.file_name,'.min.')=0
                UNION ALL

                SELECT 'ORDS_METADATA',sys_context('userenv','current_schema')
                FROM dual
                UNION ALL

                SELECT 'GRANT','OBJECT_GRANT'
                FROM user_tab_privs
                WHERE grantee=sys_context('userenv','current_schema') 
                AND grantor='ADMIN'
                AND ROWNUM=1
                UNION ALL

                SELECT 'GRANT','SYSTEM_GRANT'
                FROM user_tab_privs
                WHERE grantee=sys_context('userenv','current_schema') 
                AND grantor='ADMIN'
                AND ROWNUM=1
            )
        ORDER BY DECODE(object_type,'GRANT',1,'APEX_APPLICATION',2,3),object_name;

        FOR i IN 1..l_backup.COUNT
        LOOP
            l_file_path:=l_backup(i).object_type||'.'||l_backup(i).object_name;
            pck_core.log('Backing up to github - ' || l_file_path);

            l_clob:='';

            CASE l_backup(i).object_type
                WHEN 'APEX_APPLICATION' THEN
                    l_files:=apex_export.get_application(p_application_id => l_backup(i).object_name, p_with_date=>true);
                    l_clob:=l_files(1).contents;

                WHEN 'APEX_STATIC_FILE' THEN
                    SELECT file_content 
                      INTO l_blob 
                      FROM APEX_APPLICATION_STATIC_FILES 
                     WHERE application_id=SUBSTR(l_backup(i).object_name,1,INSTR(l_backup(i).object_name,'.')-1) 
                       AND file_name=SUBSTR(l_backup(i).object_name,INSTR(l_backup(i).object_name,'.')+1);

                WHEN 'ORDS_METADATA' THEN
                    SELECT ords_metadata.ords_export.export_schema() 
                      INTO l_clob 
                      FROM dual;

                WHEN 'GRANT' THEN
                    dbms_metadata.set_transform_param(dbms_metadata.session_transform,'EMIT_SCHEMA',true);
                    l_clob:=LTRIM(LTRIM(dbms_metadata.get_granted_ddl(l_backup(i).object_name,sys_context('userenv','current_schema')),chr(13)||chr(10)));
                    l_clob:=REPLACE(l_clob,'"','');
                    dbms_metadata.set_transform_param(dbms_metadata.session_transform,'EMIT_SCHEMA',false);

                ELSE
                    l_clob:=LTRIM(LTRIM(dbms_metadata.get_ddl(l_backup(i).object_type,l_backup(i).object_name),chr(13)||chr(10)));
                    IF (l_backup(i).object_type='TABLE') THEN
                        SELECT COUNT(*) INTO n FROM dual WHERE EXISTS
                            (
                                SELECT null FROM user_tab_comments WHERE table_name=l_backup(i).object_name AND comments IS NOT NULL
                            )
                            OR EXISTS
                            (
                                SELECT null FROM user_col_comments WHERE table_name=l_backup(i).object_name AND comments IS NOT NULL
                            );                            
                        IF (n<>0) THEN
                            l_clob:=l_clob || chr(10) || LTRIM(LTRIM(dbms_metadata.get_dependent_ddl('COMMENT',l_backup(i).object_name),chr(13)||chr(10)));
                        END IF;
                        FOR C IN (SELECT dbms_metadata.get_ddl('INDEX', index_name, table_owner) ddl
                                    FROM user_indexes
                                   WHERE table_name=l_backup(i).object_name
                                     AND index_type<>'LOB')
                        LOOP
                            l_clob:=l_clob || chr(10) || C.ddl;
                        END LOOP;
                        FOR C IN (SELECT dbms_metadata.get_ddl('CONSTRAINT', constraint_name, owner) ddl
                                    FROM user_constraints
                                   WHERE table_name=l_backup(i).object_name
                                     AND constraint_type='C')
                        LOOP
                            l_clob:=l_clob || chr(10) || C.ddl;
                        END LOOP;  
                    END IF; 
            END CASE;

            IF (l_clob IS NOT NULL) THEN
                l_blob:=apex_util.clob_to_blob(l_clob);
            END IF;

            dbms_cloud_repo.put_file(repo=>p_repo, file_path=>l_file_path, contents=>l_blob);

        END LOOP;

        EXCEPTION
            WHEN OTHERS THEN
                pck_core.log_error;
                RAISE;
    END;

    /*
    **  Daily job run by dbms_scheduler
    */
    PROCEDURE daily_job IS 
        l_repo CLOB;
    BEGIN
        l_repo := dbms_cloud_repo.init_github_repo(
            credential_name => 'GITHUB_CRED', 
            owner => 'xsf3190', 
            repo_name => 'oracle-to-github-backup');

        datapump_backup(l_repo);
        github_backup(l_repo);

        EXCEPTION
            WHEN OTHERS THEN
                pck_core.log_error;
                RAISE;
    END;

end;
/